{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://colab.research.google.com/github/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb#scrollTo=StbPlIyKDP9E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the transformers library and additional libraries if looking process\n",
    "\n",
    "!pip install -q transformers\n",
    "\n",
    "# Code for TPU packages install\n",
    "# !curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "# !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing stock ML Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from collections import Counter\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Most_common_label(label_list):\n",
    "    label = Counter(label_list).most_common(1)[0][0]\n",
    "    inx = sort_order[label]  # Most frequent label\n",
    "    L = [0 for i in range(len(unique_labels))]\n",
    "    L[inx] = 1\n",
    "    return L\n",
    "\n",
    "\n",
    "def Soft_label(label_list):\n",
    "    numeric_annotations = [sort_order[label] for label in label_list]\n",
    "    return np.bincount(numeric_annotations, minlength=len(unique_labels)) / len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>educational_value_labels</th>\n",
       "      <th>problematic_content_label_present</th>\n",
       "      <th>Final_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>Verdens militærbyrde steg ikke sidste år!\\nUSA...</td>\n",
       "      <td>[Minimal, Minimal, Minimal]</td>\n",
       "      <td>False</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Den seneste tids meget varme vejr har gjort øe...</td>\n",
       "      <td>[Minimal, Minimal, Basic]</td>\n",
       "      <td>False</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Veterandampskibet S/S Bjørn skal på værft for ...</td>\n",
       "      <td>[Minimal, Minimal]</td>\n",
       "      <td>False</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Det mener Kurt Krogsgaard fra Business Consult...</td>\n",
       "      <td>[Minimal, None]</td>\n",
       "      <td>False</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Dine kinder synes lidt slapne? De mangler en s...</td>\n",
       "      <td>[Basic, None, None]</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "935  Verdens militærbyrde steg ikke sidste år!\\nUSA...   \n",
       "250  Den seneste tids meget varme vejr har gjort øe...   \n",
       "54   Veterandampskibet S/S Bjørn skal på værft for ...   \n",
       "80   Det mener Kurt Krogsgaard fra Business Consult...   \n",
       "211  Dine kinder synes lidt slapne? De mangler en s...   \n",
       "\n",
       "        educational_value_labels  problematic_content_label_present  \\\n",
       "935  [Minimal, Minimal, Minimal]                              False   \n",
       "250    [Minimal, Minimal, Basic]                              False   \n",
       "54            [Minimal, Minimal]                              False   \n",
       "80               [Minimal, None]                              False   \n",
       "211          [Basic, None, None]                              False   \n",
       "\n",
       "         Final_label  \n",
       "935  [1, 0, 0, 0, 0]  \n",
       "250  [1, 0, 0, 0, 0]  \n",
       "54   [1, 0, 0, 0, 0]  \n",
       "80   [1, 0, 0, 0, 0]  \n",
       "211  [0, 1, 0, 0, 0]  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########\n",
    "DATASET = pd.read_parquet(\"hf://datasets/data-is-better-together/fineweb-c/dan_Latn/train-00000-of-00001.parquet\")\n",
    "PROBLEMATIC_CONTENT = False\n",
    "LABEL_FUNCTION = Most_common_label\n",
    "#########\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"text\"] = DATASET[\"text\"]\n",
    "df[\"educational_value_labels\"] = DATASET[\"educational_value_labels\"]\n",
    "df[\"problematic_content_label_present\"] = DATASET[\"problematic_content_label_present\"]\n",
    "\n",
    "\n",
    "# REMOVE PROBLEMATIC LABELS FROM DATASET\n",
    "df = df[df['problematic_content_label_present'] == PROBLEMATIC_CONTENT]\n",
    "\n",
    "unique_labels = df[\"educational_value_labels\"].explode().unique().tolist()\n",
    "sort_order = {\n",
    "    \"None\": unique_labels.index(\"None\"),\n",
    "    \"Minimal\": unique_labels.index(\"Minimal\"),\n",
    "    \"Basic\": unique_labels.index(\"Basic\"),\n",
    "    \"Good\": unique_labels.index(\"Good\"),\n",
    "    \"Excellent\": unique_labels.index(\"Excellent\"),\n",
    "}\n",
    "\n",
    "# Process Data labels\n",
    "df[\"Final_label\"] = df[\"educational_value_labels\"].apply(LABEL_FUNCTION)\n",
    "\n",
    "# Display sample rows\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Minimal', 'None', 'Basic', 'Excellent', 'Good']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame()\n",
    "new_df[\"text\"] = df[\"text\"]\n",
    "new_df[\"labels\"] = df[\"Final_label\"]\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 128\n",
    "TRAIN_SIZE = 0.8\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (806, 2)\n",
      "TRAIN Dataset: (645, 2)\n",
      "TEST Dataset: (161, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = TRAIN_SIZE\n",
    "train_data=new_df.sample(frac=train_size,random_state=200)\n",
    "test_data=new_df.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "\n",
    "training_set = MultiLabelDataset(train_data, tokenizer, MAX_LEN)\n",
    "testing_set = MultiLabelDataset(test_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
